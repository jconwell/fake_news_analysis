{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fuzzy-conditions",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "There are two topics to explore: TF-IDF and Stopwords. Be sure to add analysis markdown cells to record any insights you learned, any questions that popped into your head along the way, and any discussion points you want to talk about next time we meet.\n",
    "    \n",
    "Add new cells to do the TFIDF work just below where `df.head(10)` is printed out, above the `Stopwords` section.\n",
    "\n",
    "_Important Note: if you find something interesting in the data that you want to explore, but it isn't part of the homework, immediatly stop what you are doing and EXPLORE IT! Being curious and digging into interesting patterns is more important than completing homework tasks. Just be sure to add markdown cells to record your questions, analysis, findings, and any questions that came up during your analysis_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-short",
   "metadata": {},
   "source": [
    "## TF-IDF: Term Frequency Inverse Document Frequency\n",
    "\n",
    "Here is a good page that describes TFIDF and how to calculate it: http://www.tfidf.com/\n",
    "\n",
    "Calculate the TFIDF scores for the following words: `smell, the, this, washington, money, road, and`\n",
    "\n",
    "How are their scores different from each other? What do you think this means?\n",
    "- how do you interpret words with low scores? What about high scores?\n",
    "\n",
    "What word in the articles has the highest and lowest TFIDF score?\n",
    "\n",
    "More TFIDF resources\n",
    "- https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html#7990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "matched-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-monday",
   "metadata": {},
   "source": [
    "## `news.csv` Data Set\n",
    "\n",
    "4 columns: \n",
    "- article id\n",
    "- article title\n",
    "- article text\n",
    "- lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atomic-dimension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset: (6335, 4) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "5   6903                                        Tehran, USA   \n",
       "6   7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7     95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8   4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9   2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8  Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9  Iranian negotiators reportedly have made a las...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data\n",
    "df=pd.read_csv('data/news.csv')\n",
    "\n",
    "#Get shape and head\n",
    "shape = df.shape\n",
    "print(f\"shape of the dataset: {shape} \\n\")\n",
    "df.columns = ['id', 'title', 'text', 'label']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-scope",
   "metadata": {},
   "source": [
    "# TF(Term frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reported-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>words</th>\n",
       "      <th>words_count</th>\n",
       "      <th>frequencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[daniel, greenfield, a, shillman, journalism, ...</td>\n",
       "      <td>7518</td>\n",
       "      <td>{'the': 82, 'this': 6, 'and': 29, 'smell': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[google, pinterest, digg, linkedin, reddit, st...</td>\n",
       "      <td>2646</td>\n",
       "      <td>{'this': 3, 'and': 10, 'the': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[us, secretary, of, state, john, f, kerry, sai...</td>\n",
       "      <td>2543</td>\n",
       "      <td>{'this': 2, 'the': 22, 'and': 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[kaydee, king, kaydeeking, november, 9, 2016, ...</td>\n",
       "      <td>2660</td>\n",
       "      <td>{'the': 25, 'this': 3, 'and': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[it's, primary, day, in, new, york, and, front...</td>\n",
       "      <td>1840</td>\n",
       "      <td>{'and': 12, 'the': 19, 'this': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[im, not, an, immigrant, but, my, grandparents...</td>\n",
       "      <td>13333</td>\n",
       "      <td>{'the': 113, 'and': 83, 'this': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[share, this, baylee, luciani, left, screensho...</td>\n",
       "      <td>3171</td>\n",
       "      <td>{'this': 4, 'the': 34, 'and': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[a, czech, stockbroker, who, saved, more, than...</td>\n",
       "      <td>783</td>\n",
       "      <td>{'the': 9, 'and': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[hillary, clinton, and, donald, trump, made, s...</td>\n",
       "      <td>13863</td>\n",
       "      <td>{'and': 40, 'the': 141, 'money': 1, 'washingto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[iranian, negotiators, reportedly, have, made,...</td>\n",
       "      <td>4296</td>\n",
       "      <td>{'the': 42, 'and': 11, 'this': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "5   6903                                        Tehran, USA   \n",
       "6   7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7     95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8   4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9   2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n",
       "4  It's primary day in New York and front-runners...  REAL   \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE   \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE   \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL   \n",
       "8  Hillary Clinton and Donald Trump made some ina...  REAL   \n",
       "9  Iranian negotiators reportedly have made a las...  REAL   \n",
       "\n",
       "                                               words  words_count  \\\n",
       "0  [daniel, greenfield, a, shillman, journalism, ...         7518   \n",
       "1  [google, pinterest, digg, linkedin, reddit, st...         2646   \n",
       "2  [us, secretary, of, state, john, f, kerry, sai...         2543   \n",
       "3  [kaydee, king, kaydeeking, november, 9, 2016, ...         2660   \n",
       "4  [it's, primary, day, in, new, york, and, front...         1840   \n",
       "5  [im, not, an, immigrant, but, my, grandparents...        13333   \n",
       "6  [share, this, baylee, luciani, left, screensho...         3171   \n",
       "7  [a, czech, stockbroker, who, saved, more, than...          783   \n",
       "8  [hillary, clinton, and, donald, trump, made, s...        13863   \n",
       "9  [iranian, negotiators, reportedly, have, made,...         4296   \n",
       "\n",
       "                                         frequencies  \n",
       "0      {'the': 82, 'this': 6, 'and': 29, 'smell': 1}  \n",
       "1                  {'this': 3, 'and': 10, 'the': 14}  \n",
       "2                   {'this': 2, 'the': 22, 'and': 7}  \n",
       "3                   {'the': 25, 'this': 3, 'and': 4}  \n",
       "4                  {'and': 12, 'the': 19, 'this': 2}  \n",
       "5                {'the': 113, 'and': 83, 'this': 10}  \n",
       "6                  {'this': 4, 'the': 34, 'and': 12}  \n",
       "7                               {'the': 9, 'and': 1}  \n",
       "8  {'and': 40, 'the': 141, 'money': 1, 'washingto...  \n",
       "9                  {'the': 42, 'and': 11, 'this': 1}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ref. https://stackoverflow.com/questions/49941646/python-counter-function-to-count-words-in-documents-with-more-then-one-occurre\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "target_words = ['smell', 'the', 'this', 'washington', 'money', 'road', 'and']\n",
    "\n",
    "df['words'] = df.text.str.replace(r'[(,“,”,),%,$,+,.,\\,,@,—,‘,’,!,;]', '').str.lower().str.strip().str.split(' ')\n",
    "df['words_count'] = df['text'].str.len()\n",
    "# df['words'] = [word for word in df['words']]\n",
    "\n",
    "\n",
    "df['frequencies'] = df['words'].apply(\n",
    "    lambda words: \n",
    "    Counter({k: v for k,v in Counter(words).items() if k in target_words}))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "essential-farmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>and</th>\n",
       "      <th>smell</th>\n",
       "      <th>money</th>\n",
       "      <th>washington</th>\n",
       "      <th>road</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8476</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10294</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3608</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10142</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>875</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   the  this  and  smell  money  washington  road     id label  words_count\n",
       "0   82     6   29      1      0           0     0   8476  FAKE         7518\n",
       "1   14     3   10      0      0           0     0  10294  FAKE         2646\n",
       "2   22     2    7      0      0           0     0   3608  REAL         2543\n",
       "3   25     3    4      0      0           0     0  10142  FAKE         2660\n",
       "4   19     2   12      0      0           0     0    875  REAL         1840"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transpose = pd.DataFrame.from_dict(df['frequencies'].to_dict())\\\n",
    "                    .transpose().fillna(0).astype(int)\n",
    "df_transpose['id'] = df['id']\n",
    "df_transpose['label'] = df['label']\n",
    "df_transpose['words_count'] = df['words_count']\n",
    "df_transpose.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "treated-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>and</th>\n",
       "      <th>smell</th>\n",
       "      <th>money</th>\n",
       "      <th>washington</th>\n",
       "      <th>road</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8476</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10294</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10142</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>875</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6903</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>13333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "      <td>REAL</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4869</td>\n",
       "      <td>REAL</td>\n",
       "      <td>13863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2909</td>\n",
       "      <td>REAL</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        the      this       and     smell     money  washington  road     id  \\\n",
       "0  0.010907  0.000798  0.003857  0.000133  0.000000    0.000000   0.0   8476   \n",
       "1  0.005291  0.001134  0.003779  0.000000  0.000000    0.000000   0.0  10294   \n",
       "2  0.008651  0.000786  0.002753  0.000000  0.000000    0.000000   0.0   3608   \n",
       "3  0.009398  0.001128  0.001504  0.000000  0.000000    0.000000   0.0  10142   \n",
       "4  0.010326  0.001087  0.006522  0.000000  0.000000    0.000000   0.0    875   \n",
       "5  0.008475  0.000750  0.006225  0.000000  0.000000    0.000000   0.0   6903   \n",
       "6  0.010722  0.001261  0.003784  0.000000  0.000000    0.000000   0.0   7341   \n",
       "7  0.011494  0.000000  0.001277  0.000000  0.000000    0.000000   0.0     95   \n",
       "8  0.010171  0.000000  0.002885  0.000000  0.000072    0.000072   0.0   4869   \n",
       "9  0.009777  0.000233  0.002561  0.000000  0.000000    0.000000   0.0   2909   \n",
       "\n",
       "  label  words_count  \n",
       "0  FAKE         7518  \n",
       "1  FAKE         2646  \n",
       "2  REAL         2543  \n",
       "3  FAKE         2660  \n",
       "4  REAL         1840  \n",
       "5  FAKE        13333  \n",
       "6  FAKE         3171  \n",
       "7  REAL          783  \n",
       "8  REAL        13863  \n",
       "9  REAL         4296  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TF: term frequency from https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "tf = df_transpose.copy()\n",
    "tf[target_words] = tf[target_words].div(tf['words_count'], axis=0)\n",
    "tf.head(10)\n",
    "# tf.to_csv('data/tf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-princess",
   "metadata": {},
   "source": [
    "# IDF(Inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "veterinary-complement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>and</th>\n",
       "      <th>smell</th>\n",
       "      <th>money</th>\n",
       "      <th>washington</th>\n",
       "      <th>road</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8476</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10294</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3608</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10142</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>875</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6903</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>13333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7341</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>95</td>\n",
       "      <td>REAL</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4869</td>\n",
       "      <td>REAL</td>\n",
       "      <td>13863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2909</td>\n",
       "      <td>REAL</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    the   this   and  smell  money  washington   road     id label  \\\n",
       "0  True   True  True   True  False       False  False   8476  FAKE   \n",
       "1  True   True  True  False  False       False  False  10294  FAKE   \n",
       "2  True   True  True  False  False       False  False   3608  REAL   \n",
       "3  True   True  True  False  False       False  False  10142  FAKE   \n",
       "4  True   True  True  False  False       False  False    875  REAL   \n",
       "5  True   True  True  False  False       False  False   6903  FAKE   \n",
       "6  True   True  True  False  False       False  False   7341  FAKE   \n",
       "7  True  False  True  False  False       False  False     95  REAL   \n",
       "8  True  False  True  False   True        True  False   4869  REAL   \n",
       "9  True   True  True  False  False       False  False   2909  REAL   \n",
       "\n",
       "   words_count  \n",
       "0         7518  \n",
       "1         2646  \n",
       "2         2543  \n",
       "3         2660  \n",
       "4         1840  \n",
       "5        13333  \n",
       "6         3171  \n",
       "7          783  \n",
       "8        13863  \n",
       "9         4296  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From df_sample, convert word(term) frequency to boolean type.\n",
    "# For calculate DF, we needs check if the word exists on the document or not.\n",
    "\n",
    "idf_prep = df_transpose.copy()\n",
    "idf_prep[target_words] = idf_prep[target_words].apply(lambda x: x > 0)\n",
    "idf_prep.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "public-palestine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smell         5.288109\n",
       "the           0.025257\n",
       "this          0.254612\n",
       "washington    1.434643\n",
       "money         1.853114\n",
       "road          3.181691\n",
       "and           0.061355\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate IDF: inverse document frequency smooth from https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "\n",
    "number_of_docs = idf_prep.shape[0] #6335\n",
    "doc_freq = idf_prep[target_words].sum()\n",
    "\n",
    "idf = np.log(number_of_docs/doc_freq)\n",
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-privacy",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "attractive-senator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>and</th>\n",
       "      <th>smell</th>\n",
       "      <th>money</th>\n",
       "      <th>washington</th>\n",
       "      <th>road</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8476</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10294</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3608</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10142</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>875</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4490</td>\n",
       "      <td>REAL</td>\n",
       "      <td>4124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8062</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>14343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>8622</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>12013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4021</td>\n",
       "      <td>REAL</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4330</td>\n",
       "      <td>REAL</td>\n",
       "      <td>4866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           the      this       and     smell     money  washington      road  \\\n",
       "0     0.000274  0.000202  0.000236  0.000701  0.000000    0.000000  0.000000   \n",
       "1     0.000133  0.000288  0.000231  0.000000  0.000000    0.000000  0.000000   \n",
       "2     0.000217  0.000199  0.000168  0.000000  0.000000    0.000000  0.000000   \n",
       "3     0.000236  0.000286  0.000092  0.000000  0.000000    0.000000  0.000000   \n",
       "4     0.000258  0.000274  0.000396  0.000000  0.000000    0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...         ...       ...   \n",
       "6330  0.000202  0.000062  0.000089  0.000000  0.000000    0.000348  0.000000   \n",
       "6331  0.000276  0.000124  0.000389  0.000000  0.000000    0.000300  0.000000   \n",
       "6332  0.000360  0.000127  0.000235  0.000000  0.000617    0.000717  0.000265   \n",
       "6333  0.000219  0.000181  0.000183  0.000000  0.000263    0.000000  0.000000   \n",
       "6334  0.000192  0.000314  0.000139  0.000000  0.000381    0.000295  0.000000   \n",
       "\n",
       "         id label  words_count  \n",
       "0      8476  FAKE         7549  \n",
       "1     10294  FAKE         2654  \n",
       "2      3608  REAL         2559  \n",
       "3     10142  FAKE         2673  \n",
       "4       875  REAL         1860  \n",
       "...     ...   ...          ...  \n",
       "6330   4490  REAL         4124  \n",
       "6331   8062  FAKE        14343  \n",
       "6332   8622  FAKE        12013  \n",
       "6333   4021  REAL         7043  \n",
       "6334   4330  REAL         4866  \n",
       "\n",
       "[6335 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = tf.copy()\n",
    "tfidf[target_words] = tf[target_words] * idf\n",
    "\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-corruption",
   "metadata": {},
   "source": [
    "## JP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-arthur",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "TODO: \n",
    "\n",
    "Here are a couple of links about `stopwords` to read. \n",
    "- https://kavita-ganesan.com/what-are-stop-words/\n",
    "- https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html\n",
    "\n",
    "The python NLP toolkit NLTK has a set of built in stopwords it uses for it's algorithms. Install NLTK \n",
    "\n",
    "`pip install nktp`\n",
    "\n",
    "You'll also need to install some of the NLTK resources. Go to this link and follow the cmd line install instructions: https://www.nltk.org/data.html#command-line-installation\n",
    "\n",
    "`python -m nltk.downloader stopwords`\n",
    "\n",
    "Run the below code to print out the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unnecessary-garage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to install the natural language toolkip\n",
    "# $ pip install nltk\n",
    "\n",
    "# to install the \"stopwords\" resource\n",
    "# $ python -m nltk.downloader stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-strategy",
   "metadata": {},
   "source": [
    "### Questions: \n",
    "Given what you learned about TF-IDF, do you think stopwords will have a high TFIDF score or a low score? \n",
    "\n",
    "Why might it be useful to remove stopwords from the text when doing NLP machine learning? What types of words are left over after stopwords are removed?\n",
    "\n",
    "What are some of the potential limitations from removing all the english stopwords when doing news analysis?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
