{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: turn the FakeNews text column into tfidf vectors the easy way\n",
    "  \n",
    "Vocab:\n",
    "- corpus: set of all documents in a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `news.csv` Data Set\n",
    "\n",
    "4 columns: \n",
    "- article id\n",
    "- article title\n",
    "- article text\n",
    "- lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset: (6335, 4) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7          95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8        4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9        2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8  Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9  Iranian negotiators reportedly have made a las...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data\n",
    "df=pd.read_csv('data/news.csv')\n",
    "\n",
    "#Get shape and head\n",
    "shape = df.shape\n",
    "print(f\"shape of the dataset: {shape} \\n\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Framework API Patterns: Transformers and Estimators\n",
    "\n",
    "Machine learning pipelines take a raw dataset and then transform the data over a series of steps and finally outputs some prediction. For example, text documents -> tokenization -> word counts -> idf calculation -> tfidf calculation -> build classification model -> predictions\n",
    "\n",
    "The individual steps in a pipeline are called Transformers. Some Transformers can take the input data and directly transform it without any understanding of the full dataset. For example, a stopword filter transformer might take a set of document token arrays, and remove stopwords from each document token array.\n",
    "\n",
    "Transformers usually have a `transform()` function to do it's work. \n",
    "\n",
    "Other types of Transformers need to capture some understanding of the entire dataset before it can Transform the input data. For example a min/max normalization transformer needs to pass over the entire data set once to figure out the minimum and maximum values, then it'll pass over the dataset a second time and calculate the min/max normalization. \n",
    "\n",
    "These types of Transformers are called Estimators and usually have a `fit()` function which will do the first pass over the data and calculate it's required state (min and max values), and returns a Transformer that has this state. Then you can call `transform()` on this object to transform the data (calc min/max norms)\n",
    "\n",
    "Scikit Learn, Spark, and a few others I've run across follow this pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenization & Token Counts\n",
    "\n",
    "CountVectorizer: Converts a collection of text documents into a matrix of token counts\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = ['this is the first document',\n",
    "           'this document is the second document',\n",
    "           'and this is the third one',\n",
    "           'is this the first document',         \n",
    "         ]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "estimator = vectorizer.fit(corpus)\n",
    "X_train_counts = estimator.transform(corpus)\n",
    "\n",
    "X_train_counts = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# dictionary of all terms in corpus\n",
    "#     Warning: term overload...this does not mean a python dict, it's a dictionary in the \"list of words\" sense.\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "# token count marix from corpus\n",
    "X_train_counts.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Run the text column from the FakeNews dataset through the CountVectorizer\n",
    "\n",
    "Task 1a:\n",
    "- turn the raw \"text\" column into a count vector\n",
    "  - Try to keep all data in the pandas dataframe. So when creating the count vectors, put them back into the pandas dataframe as a new column\n",
    "- what is the size of the corpus dictionary?\n",
    "- what is the shape of the fitted document token count matrix\n",
    "- from a TF-IDF perspective, how does the output of the CountVectorizer relate to the TF-IDF calculation\n",
    "\n",
    "Task 1b:\n",
    "- look at the CountVectorizer documentation and find the `min_df` and `max_df` parameters to the CountVectorizer constructor\n",
    "  - use these params to filter out terms (tokens) that are only in 5 documents or less\n",
    "  - use these params to filter out terms (tokens) that are in 95% of the docuemnts or more\n",
    "- what is the size of the corpus dictionary?\n",
    "- why are these two types of term filters useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build count matrix for Fake News dataset, put it back on the data frame as a new field\n",
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(df[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_vector'] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>count_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>(0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>(0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>(0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>(0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>(0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n",
       "4  It's primary day in New York and front-runners...  REAL   \n",
       "\n",
       "                                        count_vector  \n",
       "0    (0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...  \n",
       "1    (0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...  \n",
       "2    (0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...  \n",
       "3    (0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...  \n",
       "4    (0, 15786)\\t1\\n  (0, 26358)\\t1\\n  (0, 54359)...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out of curiousity, what's at the top and bottom of the dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '000000031',\n",
       " '00000031',\n",
       " '000035',\n",
       " '00006',\n",
       " '0001',\n",
       " '0001pt',\n",
       " '0002',\n",
       " '000billion',\n",
       " '000ft',\n",
       " '000km',\n",
       " '000x',\n",
       " '001',\n",
       " '0011',\n",
       " '002',\n",
       " '003',\n",
       " '004',\n",
       " '004s',\n",
       " '005',\n",
       " '005s',\n",
       " '006',\n",
       " '00684',\n",
       " '006s',\n",
       " '007',\n",
       " '007s',\n",
       " '008',\n",
       " '008s',\n",
       " '009']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numbers. That's not super surprising, I guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['שני',\n",
       " 'שעת',\n",
       " 'שתי',\n",
       " 'תאמצנה',\n",
       " 'תוצאה',\n",
       " 'תחל',\n",
       " 'תיירות',\n",
       " 'תנותק',\n",
       " 'תעודת',\n",
       " 'תתרכז',\n",
       " 'أن',\n",
       " 'إجلاء',\n",
       " 'الأمر',\n",
       " 'الجرحى',\n",
       " 'الدولية',\n",
       " 'القادمون',\n",
       " 'اللجنة',\n",
       " 'تحتاج',\n",
       " 'تعرفه',\n",
       " 'تنجح',\n",
       " 'حلب',\n",
       " 'عربي',\n",
       " 'عن',\n",
       " 'لم',\n",
       " 'ما',\n",
       " 'محاولات',\n",
       " 'من',\n",
       " 'هذا',\n",
       " 'والمرضى',\n",
       " 'ยงade']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WTF? \n",
    "\n",
    "I had assumed that the articles in the dataset were pure English. That's clearly not true. Reading the entries, it looks like the posts containing these words are quoting people who posted in those languages. I'm not sure this changes anything about the analysis so far, but will have to consider that if we do English-specific things to the text later, it might do surprising things to Arabic or Hebrew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dict length: 67659\n",
      "(6335, 67659)\n"
     ]
    }
   ],
   "source": [
    "# what's the size of the corpus dictionary?\n",
    "print(f\"feature dict length: {len(vectorizer.get_feature_names())}\")\n",
    "# what's the shape of the counts matrix\n",
    "print(f\"{counts.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from a TF-IDF perspective, how does the output of the CountVectorizer relate to the TF-IDF calculation\n",
    "\n",
    "In the manual computation of the TF-IDF, I had a \"term_count\", which was the number of times a term occurred in the given doc, and the tf was then just the term_count of that term divided by the # of terms in the doc. The CountVectorizer is that term_count, precomputed. To get the TF, you'll need to sum the whole vector to get the total # of terms in the document, but that's fairly trivial for a vector of numbers. \n",
    "\n",
    "To get the IDF for a given term, you could sum across the docs at a fixed point in the vector, corresponding to the term you're looking for. So, the CountVectorizer is pre-computing a few of the steps needed for TF-IDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TFIDF Vectors\n",
    "\n",
    "TfidfTransformer: Converts a count matrix into a tfidf matrix\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True, smooth_idf=True).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "# dictionary term idf values\n",
    "print(tf_transformer.idf_)\n",
    "\n",
    "# token count marix from corpus\n",
    "X_train_tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Run the token count data (that used the `min_df` and `max_df` parameters) from the FakeNews dataset through the TfidfTransformer\n",
    "\n",
    "- What's different between the counts matrix and the tfidf matrix?\n",
    "\n",
    "so much easier than manually calculating tfidf right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tfidf for the text column in the FakeNews dataset\n",
    "\n",
    "# Stuck here. Can do by hand like:\n",
    "\n",
    "fake_news_vectorizer = CountVectorizer()\n",
    "\n",
    "fake_train_counts = fake_news_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "fake_tfidf = TfidfTransformer(use_idf=True).fit_transform(fake_train_counts)\n",
    "\n",
    "# but that's cheating, isn't it? I should be using the counts off of the dataframe itself, yes?\n",
    "\n",
    "# if I try \n",
    "# df['count_vector'] = counts\n",
    "#  \n",
    "# I get an exception that talks about a float conversion\n",
    "#\n",
    "# if I try\n",
    "# df['count_vector'] = [count for count in counts]\n",
    "# I get a also get the float conversion exception \n",
    "#\n",
    "# If I try\n",
    "# df['count_vector'] = [ar for ar in counts.toarray()]\n",
    "# I get a third exception that talks about size-1 arrays.\n",
    "#TfidfTransformer(use_idf=True).fit_transform(df['count_vector'])\n",
    "\n",
    "#\n",
    "# In theory I could just keep going with fake_train_counts, but you specifically asked me to keep as much\n",
    "# as possible in the dataframe, and everything I try to put it there is causing exceptions, so I'm a bit stuck.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x67659 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2158282 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x67659 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2158282 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_tfidf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So what's different about the train counts vs the tfidf matrices? \n",
    "\n",
    "The counts matrix is a simple count of the # of times a term appears in a given document, with one row per document. It has no cross-document feedback or relationships other than the fact that the size of the matrix depends on the # of terms in the entire corpus (so some rows in the counts matrix will have 0's for terms that don't appear in the document). The values in the tfidf matrix are pre-computed both for the inter-document frequency and the \n",
    "\n",
    "for example, I previously computed the tfidf of the word `stringing` in document 5296 manually in the previous entry. To do that here, I would just find the index of the word `stringing` in the vocab, and look that up in row 5296."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fake_news_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57613"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.index(\"stringing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_fake_tfidf = fake_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04669418737191859"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_fake_tfidf[5296][57613]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait...why is that different from what we computed when done by hand? In the `02_tfidf_stopwords` one, we got \"stringing\" in doc 5296 as a tfidf of `0.00113`. Let's make sure we're talking about the same document here, and compare the others we pulled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term smell\t tf-idf 0.0271874367707218\n",
      "term the\t tf-idf 0.4139414589780448\n",
      "term this\t tf-idf 0.03186928087028816\n",
      "term washington\t tf-idf 0.0\n",
      "term money\t tf-idf 0.0\n",
      "term road\t tf-idf 0.0\n",
      "term and\t tf-idf 0.13816442254810016\n"
     ]
    }
   ],
   "source": [
    "doc_id = 0\n",
    "for term in (\"smell\", \"the\", \"this\", \"washington\", \"money\", \"road\", \"and\"):\n",
    "    index = features.index(term)\n",
    "    print(f\"term {term}\\t tf-idf {array_fake_tfidf[doc_id][index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it looks like it's talking about the same document (the missing entries are the same) but all of the actual computed *values* are totally different. Why?  ooooh, wait: this is computing tf-idf on just the *text* part of the data frame...in the other one we computed it on the zip of the text and the title. Some of the docs had empty bodies and just titles. So, in *theory* if I make a new column that's the combination of the text and the title it should give me the same tfidf as the other doc. Partly I want to make sure I didn't f-up the computation in the earlier doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = df['text'] + df['title']\n",
    "df['combined'] = all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_vectorizer = CountVectorizer()\n",
    "\n",
    "all_words_counts = all_words_vectorizer.fit_transform(df['combined'])\n",
    "\n",
    "all_words_tf_transformer = TfidfTransformer(use_idf=True).fit(all_words_counts)\n",
    "\n",
    "all_trained_df = all_words_tf_transformer.transform(all_words_counts)\n",
    "\n",
    "all_features = all_words_vectorizer.get_feature_names()\n",
    "\n",
    "array_all_tfidf = all_trained_df.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term smell\t tf-idf 0.054309331718960276\n",
      "term the\t tf-idf 0.41168399638548503\n",
      "term this\t tf-idf 0.03177445894424231\n",
      "term washington\t tf-idf 0.0\n",
      "term money\t tf-idf 0.0\n",
      "term road\t tf-idf 0.0\n",
      "term and\t tf-idf 0.13749704067972163\n"
     ]
    }
   ],
   "source": [
    "doc_id = 0\n",
    "for term in (\"smell\", \"the\", \"this\", \"washington\", \"money\", \"road\", \"and\"):\n",
    "    index = all_features.index(term)\n",
    "    print(f\"term {term}\\t tf-idf {array_all_tfidf[doc_id][index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh. So, it did change the values, but not significantly. Certainly not enough to make them match what was computed in the previous exercise. Why? Waaaait. The common words have *high* tfidf? That's wrong. Colud the TfidfTransformer be returning a token count rather than the tfidf?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just in case I'm getting the tf here and not the tfidf, let's grab the assumed tf, and look up the computed idf and multiply them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33984039188931553"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = all_features.index(\"smell\")\n",
    "idf_maybe = all_words_tf_transformer.idf_[index]*array_all_tfidf[0][index]\n",
    "idf_maybe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The manually computed tf-idf for `smell` in doc 0 from the other worksheet was `0.001393225793371872`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4199533934266698"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = all_features.index(\"the\")\n",
    "idf_maybe2 = all_words_tf_transformer.idf_[index]*array_all_tfidf[0][index]\n",
    "idf_maybe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The manually computed tf-idf for `the` in doc 0 from the other worksheet was `0.00024359543106162621`. This is not only a different value, the assumed tf * the assumed idf for a super-common word (the) is still *higher* than the assumed computed tfidf for a less common word. This isn't right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.65965837, 2.63842081, 8.65539064, ..., 9.06085575, 9.06085575,\n",
       "       9.06085575])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_tf_transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.060855752934316"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smell_index =  all_features.index(\"s0\")\n",
    "all_words_tf_transformer.idf_[smell_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the IDF values are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Daniel Greenfield, a Shillman Journalism Fello...\n",
       "Name: combined, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1][\"combined\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to set that aside for the moment...I don't like it, since I'm *super* confident the tfidf this is returning is wrong (common words are bigger than uncommon ones, that's got to be wrong), but I'm not sure how to fix it. Any fix I figure out should be applicable to the process below, though, so let's keep going on the process.\n",
    "\n",
    "Next tasks: \n",
    "    look at the CountVectorizer documentation and find the min_df and max_df parameters to the CountVectorizer constructor\n",
    "        use these params to filter out terms (tokens) that are only in 5 documents or less\n",
    "        use these params to filter out terms (tokens) that are in 95% of the documents or more\n",
    "    what is the size of the corpus dictionary?\n",
    "    why are these two types of term filters useful?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x68637 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2172815 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x46736 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 81756 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max df as an int is the absolute value of the df above which terms are ignored. So if any word appears in less than five docs, it's ignored and \n",
    "# not shown in this count.\n",
    "uncommon_words_vectorizer = CountVectorizer(max_df=5)\n",
    "uncommon_words_counts = uncommon_words_vectorizer.fit_transform(df['combined'])\n",
    "\n",
    "uncommon_words_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the full set has 68,637 words in the corpus, the limited one has 46,736."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x1327 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1245783 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_df as a float becomes a percentage. This ignores any word that appears in less than 5% of the documents.\n",
    "common_words_vectorizer = CountVectorizer(min_df=0.05)\n",
    "common_words_counts = common_words_vectorizer.fit_transform(df[\"combined\"])\n",
    "\n",
    "common_words_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only 1,327 words. This is a reaching towards a set of stop words...things that appear in lots of the documents will tend to be commonly-used words that won't uniquely identify a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'won',\n",
       " 'word',\n",
       " 'words',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'workers',\n",
       " 'working',\n",
       " 'works',\n",
       " 'world',\n",
       " 'worse',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'wouldn',\n",
       " 'written',\n",
       " 'wrong',\n",
       " 'wrote',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'york',\n",
       " 'you',\n",
       " 'young',\n",
       " 'your']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = common_words_vectorizer.get_feature_names()\n",
    "features[-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These kinds of filters are useful since they are explicitly finding common and uncommon words across the corpus. not everything in the common words set is a stop word, but they are words that won't uniquely identify documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Pipelines\n",
    "\n",
    "Most ML frameworks have a pipeline framework, where you can add multiple different transformers into a parent transformer, then you only all `fit()` and `transform()` on the pipeline object. Internally the pipeline will call `fit()` and `transform()` on each individual transformer and output the final matrix of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "]).fit(corpus)\n",
    "\n",
    "X = pipe.transform(corpus)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count vectorizer dictionary: ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "\n",
      "tfidf transformer's idf data: [1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"count vectorizer dictionary: {pipe['count'].get_feature_names()}\")\n",
    "print()\n",
    "print(f\"tfidf transformer's idf data: {pipe['tfidf'].idf_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Build a Pipeline to generate a tfidf document matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.02742222, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build and a ML pipeline to calc tfidf on the text column of the FakeNews dataset\n",
    "fake_pipe = Pipeline([(\"count\", CountVectorizer()), (\"tfidf\", TfidfTransformer()),]).fit(df['combined'])\n",
    "\n",
    "transformed = fake_pipe.transform(df[\"combined\"])\n",
    "arr = transformed.toarray()\n",
    "arr[:4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_pipe_features = fake_pipe[\"count\"].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68637"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_pipe_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.060855752934316"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = fake_pipe_features.index(\"s0\")\n",
    "fake_pipe['tfidf'].idf_[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the plus side, this at least returns the same value for the idf we got in the previous computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: Text Normalization\n",
    "\n",
    "There are different algorithms for text normalization, such as stemming and lemitization. These algorithms aren't build into scikit-learn, but other text processing libraries like `nltk` have implementations. Both have pros and cons. I really like lemitization, but it has a heavier processing cost. \n",
    "\n",
    "Pick one, stemming or lemitization, and integrate it into your raw text to tfidf pipeline (there are articles out there on how to integrate `nltk` into a scikit-learn pipeline).  \n",
    "\n",
    "How did this change the vocabulary size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...I'm feeling contrary, so I'll try stemming. The pipeline will have to be (to my present understanding) that we run the corpus through a stemming transformer, which will change the vocab enormously, then through the CountVectorizer to get the counts of the stemmed vocab, then to the TfidfTransformer to run the TF-IDF computation on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from some reading it looks like the right way to do this is to override the analyzer in the CountVectorizer, and add the stemmer there. That also allows you to tell the CountVectorizer to use stop words also. \n",
    "\n",
    "So, our extended CountVectorizer would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    snowball_stemmer = SnowballStemmer(\"english\")\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([self.snowball_stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can make a vectorizer simply with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_vector = StemmedCountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the full stemmed pipeline would look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('count', StemmedCountVectorizer(stop_words=\"english\")),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "]).fit(df[\"combined\"])\n",
    "\n",
    "X = pipe.transform(df[\"combined\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_features = pipe[\"count\"].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '0000', '000000031', '00000031']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['مورد', 'هذا', 'والمرضى', 'کدآمایی', 'ยงade']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_features[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46742"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipe_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming shrank the size of the feature (the vocab) by a *lot*. It was 68,637 before stemming, 46,742 after. This probably didn't change the likely un-stemmable things (the numbers at the start of the features) or the non-english things at the end of the features. It might be interesting to drop those entirely since the analysis we're doing is entirely English-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
